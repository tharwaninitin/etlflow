<!DOCTYPE html><html><head><title>EtlFlow: Dataproc</title><meta charset="utf-8" /><meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" /><meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="author" content="com.github.tharwaninitin" /><meta name="description" content="Functional library in Scala for writing ETL jobs" /><meta name="og:image" content="/etlflow/site/img/poster.png" /><meta name="image" property="og:image" content="/etlflow/site/img/poster.png" /><meta name="og:title" content="EtlFlow: Dataproc" /><meta name="title" property="og:title" content="EtlFlow: Dataproc" /><meta name="og:site_name" content="EtlFlow" /><meta name="og:url" content="" /><meta name="og:type" content="website" /><meta name="og:description" content="Functional library in Scala for writing ETL jobs" /><link rel="icon" type="image/png" href="/etlflow/site/img/favicon.png" /><meta name="twitter:title" content="EtlFlow: Dataproc" /><meta name="twitter:image" content="https://tharwaninitin.github.io/etlflow/site//etlflow/site/img/poster.png" /><meta name="twitter:description" content="Functional library in Scala for writing ETL jobs" /><meta name="twitter:card" content="summary_large_image" /><link rel="icon" type="image/png" sizes="16x16" href="/etlflow/site/img/favicon16x16.png" /><link rel="icon" type="image/png" sizes="24x24" href="/etlflow/site/img/favicon24x24.png" /><link rel="icon" type="image/png" sizes="32x32" href="/etlflow/site/img/favicon32x32.png" /><link rel="icon" type="image/png" sizes="48x48" href="/etlflow/site/img/favicon48x48.png" /><link rel="icon" type="image/png" sizes="57x57" href="/etlflow/site/img/favicon57x57.png" /><link rel="icon" type="image/png" sizes="60x60" href="/etlflow/site/img/favicon60x60.png" /><link rel="icon" type="image/png" sizes="64x64" href="/etlflow/site/img/favicon64x64.png" /><link rel="icon" type="image/png" sizes="70x70" href="/etlflow/site/img/favicon70x70.png" /><link rel="icon" type="image/png" sizes="72x72" href="/etlflow/site/img/favicon72x72.png" /><link rel="icon" type="image/png" sizes="76x76" href="/etlflow/site/img/favicon76x76.png" /><link rel="icon" type="image/png" sizes="96x96" href="/etlflow/site/img/favicon96x96.png" /><link rel="icon" type="image/png" sizes="114x114" href="/etlflow/site/img/favicon114x114.png" /><link rel="icon" type="image/png" sizes="120x120" href="/etlflow/site/img/favicon120x120.png" /><link rel="icon" type="image/png" sizes="128x128" href="/etlflow/site/img/favicon128x128.png" /><link rel="icon" type="image/png" sizes="144x144" href="/etlflow/site/img/favicon144x144.png" /><link rel="icon" type="image/png" sizes="150x150" href="/etlflow/site/img/favicon150x150.png" /><link rel="icon" type="image/png" sizes="152x152" href="/etlflow/site/img/favicon152x152.png" /><link rel="icon" type="image/png" sizes="196x196" href="/etlflow/site/img/favicon196x196.png" /><link rel="icon" type="image/png" sizes="310x310" href="/etlflow/site/img/favicon310x310.png" /><link rel="icon" type="image/png" sizes="310x150" href="/etlflow/site/img/favicon310x150.png" /><link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/bootstrap/3.3.7/css/bootstrap.min.css" /><link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/font-awesome/4.7.0/css/font-awesome.min.css" /><link rel="stylesheet" href="/etlflow/site/highlight/styles/vs.css" /><link rel="stylesheet" href="/etlflow/site/css/pattern-style.css" /></head><body class="docs"><div id="wrapper"><div id="sidebar-wrapper"><ul id="sidebar" class="sidebar-nav"><li class="sidebar-brand"><a href="/etlflow/site/" class="brand"><div class="brand-wrapper"><span>EtlFlow</span></div></a></li> <li><a href="/etlflow/site/docs/index.html" class="">Introduction</a></li> <li><a href="/etlflow/site/docs/core.html" class="">Quickstart (Core)</a></li> <li><a href="/etlflow/site/docs/server.html" class="">Quickstart (Server)</a></li> <li><a href="/etlflow/site/docs/steps.html" class="">Steps</a> <ul class="sub-section"> <li><a href="/etlflow/site/docs/spark.html" class="">Spark</a></li> <li><a href="/etlflow/site/docs/bigquery.html" class="">BigQuery</a></li> <li><a href="/etlflow/site/docs/gcs.html" class="">GCS</a></li> <li><a href="/etlflow/site/docs/s3.html" class="">S3</a></li> <li><a href="/etlflow/site/docs/jdbc.html" class="">JDBC</a></li> <li><a href="/etlflow/site/docs/http.html" class="">HTTP</a></li> <li><a href="/etlflow/site/docs/redisquery.html" class="">Redis</a></li> <li><a href="/etlflow/site/docs/sendmail.html" class="">Send Mail</a></li> <li><a href="/etlflow/site/docs/dp.html" class=" active ">Dataproc</a></li> <li><a href="/etlflow/site/docs/parallel.html" class="">Parallel Step</a></li> <li><a href="/etlflow/site/docs/cloud_steps.html" class="">Cloud</a></li> <li><a href="/etlflow/site/docs/remote.html" class="">Remote</a></li></ul></li> <li><a href="/etlflow/site/docs/sensors.html" class="">Sensors</a> <ul class="sub-section"> <li><a href="/etlflow/site/docs/gcssensor.html" class="">GCS Sensor</a></li> <li><a href="/etlflow/site/docs/s3sensor.html" class="">S3 Sensor</a></li></ul></li> <li><a href="/etlflow/site/docs/job.html" class="">Job</a></li> <li><a href="/etlflow/site/docs/executors.html" class="">Executors</a> <ul class="sub-section"> <li><a href="/etlflow/site/docs/local.html" class="">Local Executor</a></li> <li><a href="/etlflow/site/docs/local_subprocess.html" class="">Local Sub-Process Executor</a></li> <li><a href="/etlflow/site/docs/dataproc.html" class="">Dataproc Executor</a></li> <li><a href="/etlflow/site/docs/kubernetes.html" class="">Kubernetes Executor</a></li></ul></li> <li><a href="/etlflow/site/docs/example.html" class="">Example Project</a></li></ul></div><div id="page-content-wrapper"><div class="nav"><div class="container-fluid"><div class="row"><div class="col-lg-12"><div class="action-menu pull-left clearfix"><a href="#menu-toggle" id="menu-toggle"><i class="fa fa-bars" aria-hidden="true"></i></a></div><ul class="pull-right"><li id="gh-eyes-item" class="hidden-xs"><a href="https://github.com/tharwaninitin/etlflow" target="_blank" rel="noopener noreferrer"><i class="fa fa-eye"></i><span>Watchers<span id="eyes" class="label label-default">--</span></span></a></li><li id="gh-stars-item" class="hidden-xs"><a href="https://github.com/tharwaninitin/etlflow" target="_blank" rel="noopener noreferrer"><i class="fa fa-star-o"></i><span>Stars<span id="stars" class="label label-default">--</span></span></a></li><li><a href="#" onclick="shareSiteTwitter('EtlFlow Functional library in Scala for writing ETL jobs');"><i class="fa fa-twitter"></i></a></li><li><a href="#" onclick="shareSiteFacebook('EtlFlow Functional library in Scala for writing ETL jobs');"><i class="fa fa-facebook"></i></a></li><li><a href="#" onclick="shareSiteGoogle();"><i class="fa fa-google-plus"></i></a></li></ul></div></div></div></div><div id="content" data-github-owner="tharwaninitin" data-github-repo="etlflow"><div class="content-wrapper"><section><h2 id="dataproc-steps">Dataproc Steps</h2>

<p><strong>This page shows different Dataproc Steps available in this library</strong></p>

<h3 id="dphivejobstep">DPHiveJobStep</h3>
<p>We can use below step when we want to trigger query on Hive Dataproc. Query should not return results for this step</p>

<div class="language-scala highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">import</span> <span class="nn">etlflow.utils.Executor.DATAPROC</span>
<span class="k">import</span> <span class="nn">etlflow.etlsteps.</span><span class="o">{</span><span class="nc">DPHiveJobStep</span><span class="o">,</span> <span class="nc">DPSparkJobStep</span><span class="o">}</span>

<span class="k">val</span> <span class="nv">dpConfig1</span> <span class="k">=</span> <span class="nc">DATAPROC</span><span class="o">(</span>
              <span class="s">"DP_PROJECT_ID"</span><span class="o">,</span>
              <span class="s">"DP_REGION"</span><span class="o">,</span>
              <span class="s">"DP_ENDPOINT"</span><span class="o">,</span>
              <span class="s">"DP_CLUSTER_NAME"</span>
            <span class="o">)</span>
<span class="c1">// dpConfig1: DATAPROC = DATAPROC(</span>
<span class="c1">//   "DP_PROJECT_ID",</span>
<span class="c1">//   "DP_REGION",</span>
<span class="c1">//   "DP_ENDPOINT",</span>
<span class="c1">//   "DP_CLUSTER_NAME"</span>
<span class="c1">// )</span>
            
<span class="k">val</span> <span class="nv">step1</span> <span class="k">=</span> <span class="nc">DPHiveJobStep</span><span class="o">(</span>
              <span class="n">name</span> <span class="k">=</span> <span class="s">"DPHiveJobStepExample"</span><span class="o">,</span>
              <span class="n">query</span> <span class="k">=</span> <span class="s">"SELECT 1 AS ONE"</span><span class="o">,</span>
              <span class="n">config</span> <span class="k">=</span> <span class="n">dpConfig1</span><span class="o">,</span>
<span class="o">)</span>
<span class="c1">// step1: DPHiveJobStep = DPHiveJobStep(</span>
<span class="c1">//   "DPHiveJobStepExample",</span>
<span class="c1">//   "SELECT 1 AS ONE",</span>
<span class="c1">//   DATAPROC("DP_PROJECT_ID", "DP_REGION", "DP_ENDPOINT", "DP_CLUSTER_NAME")</span>
<span class="c1">// )</span>
</code></pre></div></div>

<h3 id="dpsparkjobstep">DPSparkJobStep</h3>
<p>We can use below step when we want to trigger a job on Dataproc cluster from local server.</p>

<div class="language-scala highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">import</span> <span class="nn">etlflow.utils.Executor.DATAPROC</span>
<span class="k">import</span> <span class="nn">etlflow.etlsteps.</span><span class="o">{</span><span class="nc">DPHiveJobStep</span><span class="o">,</span> <span class="nc">DPSparkJobStep</span><span class="o">}</span>

<span class="k">val</span> <span class="nv">libs</span> <span class="k">=</span> <span class="s">"DP_LIBS"</span><span class="o">.</span><span class="py">split</span><span class="o">(</span><span class="s">","</span><span class="o">).</span><span class="py">toList</span>
<span class="c1">// libs: List[String] = List("DP_LIBS")</span>
<span class="k">val</span> <span class="nv">step2</span> <span class="k">=</span> <span class="nc">DPSparkJobStep</span><span class="o">(</span>
        <span class="n">name</span>        <span class="k">=</span> <span class="s">"DPSparkJobStepExample"</span><span class="o">,</span>
        <span class="n">job_name</span>    <span class="k">=</span> <span class="s">"DP_JOB_NAME"</span><span class="o">,</span>
        <span class="n">props</span>       <span class="k">=</span> <span class="nv">Map</span><span class="o">.</span><span class="py">empty</span><span class="o">,</span>
        <span class="n">config</span>      <span class="k">=</span> <span class="n">dpConfig1</span><span class="o">,</span>
        <span class="n">main_class</span>  <span class="k">=</span> <span class="s">"DP_MAIN_CLASS"</span><span class="o">,</span>
        <span class="n">libs</span>        <span class="k">=</span> <span class="n">libs</span>
<span class="o">)</span> 
<span class="c1">// step2: DPSparkJobStep = DPSparkJobStep(</span>
<span class="c1">//   "DPSparkJobStepExample",</span>
<span class="c1">//   "DP_JOB_NAME",</span>
<span class="c1">//   Map(),</span>
<span class="c1">//   DATAPROC("DP_PROJECT_ID", "DP_REGION", "DP_ENDPOINT", "DP_CLUSTER_NAME"),</span>
<span class="c1">//   "DP_MAIN_CLASS",</span>
<span class="c1">//   List("DP_LIBS")</span>
<span class="c1">// )</span>
</code></pre></div></div>

<h3 id="dpcreatestep">DPCreateStep</h3>
<p>We can use below step when we want to create new dataproc cluster.</p>

<div class="language-scala highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">import</span> <span class="nn">etlflow.etlsteps.DPCreateStep</span>
<span class="k">import</span> <span class="nn">etlflow.gcp.DataprocProperties</span>
<span class="k">import</span> <span class="nn">etlflow.utils.Executor.DATAPROC</span>


   <span class="k">val</span> <span class="nv">dpConfig2</span> <span class="k">=</span> <span class="nc">DATAPROC</span><span class="o">(</span>
              <span class="s">"DP_PROJECT_ID"</span><span class="o">,</span>
              <span class="s">"DP_REGION"</span><span class="o">,</span>
              <span class="s">"DP_ENDPOINT"</span><span class="o">,</span>
              <span class="s">"DP_CLUSTER_NAME"</span>
            <span class="o">)</span>
<span class="c1">// dpConfig2: DATAPROC = DATAPROC(</span>
<span class="c1">//   "DP_PROJECT_ID",</span>
<span class="c1">//   "DP_REGION",</span>
<span class="c1">//   "DP_ENDPOINT",</span>
<span class="c1">//   "DP_CLUSTER_NAME"</span>
<span class="c1">// )</span>

   <span class="k">val</span> <span class="nv">dpProps</span> <span class="k">=</span>  <span class="nc">DataprocProperties</span><span class="o">(</span>
          <span class="n">bucket_name</span>     <span class="k">=</span> <span class="s">"DP_BUCKET_NAME"</span><span class="o">,</span>
          <span class="n">subnet_uri</span>      <span class="k">=</span> <span class="nc">Some</span><span class="o">(</span><span class="s">"DP_SUBNET_WORK_URI"</span><span class="o">),</span>
          <span class="n">network_tags</span>    <span class="k">=</span> <span class="s">"DP_NETWORK_TAG1,DP_NETWORK_TAG2"</span><span class="o">.</span><span class="py">split</span><span class="o">(</span><span class="s">","</span><span class="o">).</span><span class="py">toList</span><span class="o">,</span>
          <span class="n">service_account</span> <span class="k">=</span> <span class="nc">Some</span><span class="o">(</span><span class="s">"DP_SERVICE_ACCOUNT"</span><span class="o">)</span>
   <span class="o">)</span>
<span class="c1">// dpProps: DataprocProperties = DataprocProperties(</span>
<span class="c1">//   "DP_BUCKET_NAME",</span>
<span class="c1">//   Some("DP_SUBNET_WORK_URI"),</span>
<span class="c1">//   List("DP_NETWORK_TAG1", "DP_NETWORK_TAG2"),</span>
<span class="c1">//   Some("DP_SERVICE_ACCOUNT"),</span>
<span class="c1">//   Some(1800L),</span>
<span class="c1">//   "n1-standard-4",</span>
<span class="c1">//   "n1-standard-4",</span>
<span class="c1">//   "1.5.4-debian10",</span>
<span class="c1">//   "pd-ssd",</span>
<span class="c1">//   400,</span>
<span class="c1">//   200,</span>
<span class="c1">//   1,</span>
<span class="c1">//   3</span>
<span class="c1">// )</span>


<span class="k">val</span> <span class="nv">step3</span> <span class="k">=</span> <span class="nc">DPCreateStep</span><span class="o">(</span>
          <span class="n">name</span>     <span class="k">=</span> <span class="s">"DPCreateStepExample"</span><span class="o">,</span>
          <span class="n">config</span>   <span class="k">=</span> <span class="n">dpConfig2</span><span class="o">,</span>
          <span class="n">props</span>    <span class="k">=</span> <span class="n">dpProps</span>
        <span class="o">)</span>
<span class="c1">// step3: DPCreateStep = etlflow.etlsteps.DPCreateStep@4d2443d7</span>
</code></pre></div></div>

<h3 id="dpdeletestep">DPDeleteStep</h3>
<p>We can use below step when we want to delete dataproc cluster.</p>

<div class="language-scala highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">import</span> <span class="nn">etlflow.utils.Executor.DATAPROC</span>
<span class="k">import</span> <span class="nn">etlflow.etlsteps.DPDeleteStep</span>

  <span class="k">val</span> <span class="nv">dpConfig3</span> <span class="k">=</span> <span class="nc">DATAPROC</span><span class="o">(</span>
              <span class="s">"DP_PROJECT_ID"</span><span class="o">,</span>
              <span class="s">"DP_REGION"</span><span class="o">,</span>
              <span class="s">"DP_ENDPOINT"</span><span class="o">,</span>
              <span class="s">"DP_CLUSTER_NAME"</span>
            <span class="o">)</span>
<span class="c1">// dpConfig3: DATAPROC = DATAPROC(</span>
<span class="c1">//   "DP_PROJECT_ID",</span>
<span class="c1">//   "DP_REGION",</span>
<span class="c1">//   "DP_ENDPOINT",</span>
<span class="c1">//   "DP_CLUSTER_NAME"</span>
<span class="c1">// )</span>

 <span class="k">val</span> <span class="nv">step</span> <span class="k">=</span> <span class="nc">DPDeleteStep</span><span class="o">(</span>
          <span class="n">name</span>     <span class="k">=</span> <span class="s">"DPDeleteStepExample"</span><span class="o">,</span>
          <span class="n">config</span>   <span class="k">=</span> <span class="n">dpConfig3</span><span class="o">,</span>
 <span class="o">)</span>
<span class="c1">// step: DPDeleteStep = etlflow.etlsteps.DPDeleteStep@200961b2</span>
</code></pre></div></div>
</section></div></div></div></div><script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/twitter-bootstrap/3.3.7/js/bootstrap.min.js"></script><script src="/etlflow/site/highlight/highlight.pack.js"></script><script>
// For all code blocks, copy the language from the containing div
// to the inner code tag (where hljs expects it to be)
const langPrefix = 'language-';
document.querySelectorAll(`div[class^='${langPrefix}']`).forEach(function(div) {
  div.classList.forEach(function(cssClass) {
    if (cssClass.startsWith(langPrefix)) {
      const lang = cssClass.substring(langPrefix.length);
      div.querySelectorAll('pre code').forEach(function(code) {
        code.classList.add(lang);
      });
    }
  });
});

hljs.configure({languages:['scala','java','bash']});
hljs.initHighlightingOnLoad();
      </script><script>console.info('\x57\x65\x62\x73\x69\x74\x65\x20\x62\x75\x69\x6c\x74\x20\x77\x69\x74\x68\x3a\x0a\x20\x20\x20\x20\x20\x20\x20\x20\x20\x5f\x5f\x20\x20\x20\x20\x5f\x5f\x20\x20\x20\x20\x20\x20\x20\x20\x20\x20\x20\x20\x20\x20\x20\x20\x20\x20\x5f\x20\x20\x20\x20\x20\x20\x20\x20\x20\x20\x20\x20\x20\x20\x20\x20\x20\x20\x20\x20\x20\x20\x5f\x20\x5f\x5f\x0a\x20\x20\x20\x5f\x5f\x5f\x5f\x5f\x2f\x20\x2f\x5f\x20\x20\x2f\x20\x2f\x5f\x20\x20\x20\x20\x20\x20\x5f\x5f\x5f\x5f\x20\x5f\x5f\x5f\x20\x20\x28\x5f\x29\x5f\x5f\x5f\x5f\x5f\x5f\x5f\x5f\x5f\x5f\x5f\x5f\x5f\x20\x20\x5f\x5f\x5f\x5f\x5f\x28\x5f\x29\x20\x2f\x5f\x5f\x5f\x5f\x20\x20\x5f\x5f\x5f\x5f\x5f\x0a\x20\x20\x2f\x20\x5f\x5f\x5f\x2f\x20\x5f\x5f\x20\x5c\x2f\x20\x5f\x5f\x2f\x5f\x5f\x5f\x5f\x5f\x2f\x20\x5f\x5f\x20\x60\x5f\x5f\x20\x5c\x2f\x20\x2f\x20\x5f\x5f\x5f\x2f\x20\x5f\x5f\x5f\x2f\x20\x5f\x5f\x20\x5c\x2f\x20\x5f\x5f\x5f\x2f\x20\x2f\x20\x5f\x5f\x2f\x20\x5f\x20\x5c\x2f\x20\x5f\x5f\x5f\x2f\x0a\x20\x28\x5f\x5f\x20\x20\x29\x20\x2f\x5f\x2f\x20\x2f\x20\x2f\x5f\x2f\x5f\x5f\x5f\x5f\x5f\x2f\x20\x2f\x20\x2f\x20\x2f\x20\x2f\x20\x2f\x20\x2f\x20\x2f\x5f\x5f\x2f\x20\x2f\x20\x20\x2f\x20\x2f\x5f\x2f\x20\x28\x5f\x5f\x20\x20\x29\x20\x2f\x20\x2f\x5f\x2f\x20\x20\x5f\x5f\x28\x5f\x5f\x20\x20\x29\x0a\x2f\x5f\x5f\x5f\x5f\x2f\x5f\x2e\x5f\x5f\x5f\x2f\x5c\x5f\x5f\x2f\x20\x20\x20\x20\x20\x2f\x5f\x2f\x20\x2f\x5f\x2f\x20\x2f\x5f\x2f\x5f\x2f\x5c\x5f\x5f\x5f\x2f\x5f\x2f\x20\x20\x20\x5c\x5f\x5f\x5f\x5f\x2f\x5f\x5f\x5f\x5f\x2f\x5f\x2f\x5c\x5f\x5f\x2f\x5c\x5f\x5f\x5f\x2f\x5f\x5f\x5f\x5f\x2f\x0a\x0a\x68\x74\x74\x70\x73\x3a\x2f\x2f\x34\x37\x64\x65\x67\x2e\x67\x69\x74\x68\x75\x62\x2e\x69\x6f\x2f\x73\x62\x74\x2d\x6d\x69\x63\x72\x6f\x73\x69\x74\x65\x73')</script><script src="/etlflow/site/js/main.js"></script></body></html>