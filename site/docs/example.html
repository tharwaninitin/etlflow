<!DOCTYPE html><html><head><title>EtlFlow: How to use Etlflow library</title><meta charset="utf-8" /><meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" /><meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="author" content="com.github.tharwaninitin" /><meta name="description" content="Functional library in Scala for writing ETL jobs" /><meta name="og:image" content="/etlflow/site/img/poster.png" /><meta name="image" property="og:image" content="/etlflow/site/img/poster.png" /><meta name="og:title" content="EtlFlow: How to use Etlflow library" /><meta name="title" property="og:title" content="EtlFlow: How to use Etlflow library" /><meta name="og:site_name" content="EtlFlow" /><meta name="og:url" content="" /><meta name="og:type" content="website" /><meta name="og:description" content="Functional library in Scala for writing ETL jobs" /><link rel="icon" type="image/png" href="/etlflow/site/img/favicon.png" /><meta name="twitter:title" content="EtlFlow: How to use Etlflow library" /><meta name="twitter:image" content="https://tharwaninitin.github.io/etlflow/site//etlflow/site/img/poster.png" /><meta name="twitter:description" content="Functional library in Scala for writing ETL jobs" /><meta name="twitter:card" content="summary_large_image" /><link rel="icon" type="image/png" sizes="16x16" href="/etlflow/site/img/favicon16x16.png" /><link rel="icon" type="image/png" sizes="24x24" href="/etlflow/site/img/favicon24x24.png" /><link rel="icon" type="image/png" sizes="32x32" href="/etlflow/site/img/favicon32x32.png" /><link rel="icon" type="image/png" sizes="48x48" href="/etlflow/site/img/favicon48x48.png" /><link rel="icon" type="image/png" sizes="57x57" href="/etlflow/site/img/favicon57x57.png" /><link rel="icon" type="image/png" sizes="60x60" href="/etlflow/site/img/favicon60x60.png" /><link rel="icon" type="image/png" sizes="64x64" href="/etlflow/site/img/favicon64x64.png" /><link rel="icon" type="image/png" sizes="70x70" href="/etlflow/site/img/favicon70x70.png" /><link rel="icon" type="image/png" sizes="72x72" href="/etlflow/site/img/favicon72x72.png" /><link rel="icon" type="image/png" sizes="76x76" href="/etlflow/site/img/favicon76x76.png" /><link rel="icon" type="image/png" sizes="96x96" href="/etlflow/site/img/favicon96x96.png" /><link rel="icon" type="image/png" sizes="114x114" href="/etlflow/site/img/favicon114x114.png" /><link rel="icon" type="image/png" sizes="120x120" href="/etlflow/site/img/favicon120x120.png" /><link rel="icon" type="image/png" sizes="128x128" href="/etlflow/site/img/favicon128x128.png" /><link rel="icon" type="image/png" sizes="144x144" href="/etlflow/site/img/favicon144x144.png" /><link rel="icon" type="image/png" sizes="150x150" href="/etlflow/site/img/favicon150x150.png" /><link rel="icon" type="image/png" sizes="152x152" href="/etlflow/site/img/favicon152x152.png" /><link rel="icon" type="image/png" sizes="196x196" href="/etlflow/site/img/favicon196x196.png" /><link rel="icon" type="image/png" sizes="310x310" href="/etlflow/site/img/favicon310x310.png" /><link rel="icon" type="image/png" sizes="310x150" href="/etlflow/site/img/favicon310x150.png" /><link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/bootstrap/3.3.7/css/bootstrap.min.css" /><link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/font-awesome/4.7.0/css/font-awesome.min.css" /><link rel="stylesheet" href="/etlflow/site/highlight/styles/vs.css" /><link rel="stylesheet" href="/etlflow/site/css/pattern-style.css" /></head><body class="docs"><div id="wrapper"><div id="sidebar-wrapper"><ul id="sidebar" class="sidebar-nav"><li class="sidebar-brand"><a href="/etlflow/site/" class="brand"><div class="brand-wrapper"><span>EtlFlow</span></div></a></li> <li><a href="/etlflow/site/docs/index.html" class="">Introduction</a></li> <li><a href="/etlflow/site/docs/core.html" class="">Quickstart (Core)</a></li> <li><a href="/etlflow/site/docs/server.html" class="">Quickstart (Server)</a></li> <li><a href="/etlflow/site/docs/steps.html" class="">Steps</a> <ul class="sub-section"> <li><a href="/etlflow/site/docs/spark.html" class="">Spark</a></li> <li><a href="/etlflow/site/docs/bigquery.html" class="">BigQuery</a></li> <li><a href="/etlflow/site/docs/gcs.html" class="">GCS</a></li> <li><a href="/etlflow/site/docs/s3.html" class="">S3</a></li> <li><a href="/etlflow/site/docs/jdbc.html" class="">JDBC</a></li> <li><a href="/etlflow/site/docs/http.html" class="">HTTP</a></li> <li><a href="/etlflow/site/docs/redisquery.html" class="">Redis</a></li> <li><a href="/etlflow/site/docs/sendmail.html" class="">Send Mail</a></li> <li><a href="/etlflow/site/docs/dp.html" class="">Dataproc</a></li> <li><a href="/etlflow/site/docs/parallel.html" class="">Parallel Step</a></li> <li><a href="/etlflow/site/docs/cloud_steps.html" class="">Cloud</a></li> <li><a href="/etlflow/site/docs/remote.html" class="">Remote</a></li></ul></li> <li><a href="/etlflow/site/docs/sensors.html" class="">Sensors</a> <ul class="sub-section"> <li><a href="/etlflow/site/docs/gcssensor.html" class="">GCS Sensor</a></li> <li><a href="/etlflow/site/docs/s3sensor.html" class="">S3 Sensor</a></li></ul></li> <li><a href="/etlflow/site/docs/job.html" class="">Job</a></li> <li><a href="/etlflow/site/docs/executors.html" class="">Executors</a> <ul class="sub-section"> <li><a href="/etlflow/site/docs/local.html" class="">Local Executor</a></li> <li><a href="/etlflow/site/docs/local_subprocess.html" class="">Local Sub-Process Executor</a></li> <li><a href="/etlflow/site/docs/dataproc.html" class="">Dataproc Executor</a></li> <li><a href="/etlflow/site/docs/kubernetes.html" class="">Kubernetes Executor</a></li></ul></li> <li><a href="/etlflow/site/docs/example.html" class="">Example Project</a></li></ul></div><div id="page-content-wrapper"><div class="nav"><div class="container-fluid"><div class="row"><div class="col-lg-12"><div class="action-menu pull-left clearfix"><a href="#menu-toggle" id="menu-toggle"><i class="fa fa-bars" aria-hidden="true"></i></a></div><ul class="pull-right"><li class="search-nav hidden-xs hidden-sm"><div id="search-dropdown"><label><i class="fa fa-search"></i>Search</label><input id="search-bar" type="text" placeholder="Enter keywords here..." onclick="displayToggleSearch(event)" /><ul id="search-dropdown-content" class="dropdown dropdown-content"></ul></div></li><li id="gh-eyes-item" class="hidden-xs to-uppercase"><a href="https://github.com/tharwaninitin/etlflow" target="_blank" rel="noopener noreferrer"><i class="fa fa-eye"></i><span>Watchers<span id="eyes" class="label label-default">--</span></span></a></li><li id="gh-stars-item" class="hidden-xs to-uppercase"><a href="https://github.com/tharwaninitin/etlflow" target="_blank" rel="noopener noreferrer"><i class="fa fa-star-o"></i><span>Stars<span id="stars" class="label label-default">--</span></span></a></li><li><a href="#" onclick="shareSiteTwitter('EtlFlow Functional library in Scala for writing ETL jobs');"><i class="fa fa-twitter"></i></a></li><li><a href="#" onclick="shareSiteFacebook('EtlFlow Functional library in Scala for writing ETL jobs');"><i class="fa fa-facebook"></i></a></li></ul></div></div></div></div><div id="content" data-github-owner="tharwaninitin" data-github-repo="etlflow"><div class="content-wrapper"><section><h2 id="how-to-use-etlflow-library">How to use Etlflow library</h2>

<p>Clone this git repo and go inside repo root folder and enter below command (make sure you have sbt and scala installed)</p>

<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>SBT_OPTS="-Xms512M -Xmx1024M -Xss2M -XX:MaxMetaspaceSize=1024M" sbt -v "project examples" console
</code></pre></div></div>

<p><strong>Import core packages</strong></p>

<div class="language-scala highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">import</span> <span class="nn">etlflow.etlsteps._</span>
<span class="k">import</span> <span class="nn">etlflow.utils._</span>
<span class="k">import</span> <span class="nn">etlflow.spark.IOType</span>
<span class="k">import</span> <span class="nn">etlflow.gcp.BQInputType</span>
</code></pre></div></div>

<p><strong>Define Job input and ouput locations</strong></p>

<div class="language-scala highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">lazy</span> <span class="k">val</span> <span class="nv">canonical_path</span><span class="k">:</span> <span class="kt">String</span> <span class="o">=</span> <span class="k">new</span> <span class="nv">java</span><span class="o">.</span><span class="py">io</span><span class="o">.</span><span class="py">File</span><span class="o">(</span><span class="s">"."</span><span class="o">).</span><span class="py">getCanonicalPath</span>
<span class="k">lazy</span> <span class="k">val</span> <span class="nv">job_properties</span><span class="k">:</span> <span class="kt">Map</span><span class="o">[</span><span class="kt">String</span>,<span class="kt">String</span><span class="o">]</span> <span class="k">=</span> <span class="nc">Map</span><span class="o">(</span>
        <span class="s">"ratings_input_path"</span> <span class="o">-&gt;</span> <span class="n">s</span><span class="s">"$canonical_path/examples/src/main/data/movies/ratings/*"</span><span class="o">,</span>
        <span class="s">"ratings_output_path"</span> <span class="o">-&gt;</span> <span class="n">s</span><span class="s">"$canonical_path/examples/src/main/data/movies/output/ratings"</span><span class="o">,</span>
        <span class="s">"ratings_output_file_name"</span> <span class="o">-&gt;</span> <span class="s">"ratings.orc"</span>
<span class="o">)</span>
</code></pre></div></div>

<p><strong>Create spark session</strong></p>

<div class="language-scala highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">import</span> <span class="nn">org.apache.spark.sql.SparkSession</span>
<span class="k">import</span> <span class="nn">org.slf4j.LoggerFactory</span>
<span class="k">import</span> <span class="nn">ch.qos.logback.classic.</span><span class="o">{</span><span class="nc">Level</span><span class="o">,</span> <span class="nc">Logger</span><span class="o">}</span>
<span class="nv">LoggerFactory</span><span class="o">.</span><span class="py">getLogger</span><span class="o">(</span><span class="s">"org"</span><span class="o">).</span><span class="py">asInstanceOf</span><span class="o">[</span><span class="kt">Logger</span><span class="o">].</span><span class="py">setLevel</span><span class="o">(</span><span class="nv">Level</span><span class="o">.</span><span class="py">WARN</span><span class="o">)</span>
<span class="nv">LoggerFactory</span><span class="o">.</span><span class="py">getLogger</span><span class="o">(</span><span class="s">"io"</span><span class="o">).</span><span class="py">asInstanceOf</span><span class="o">[</span><span class="kt">Logger</span><span class="o">].</span><span class="py">setLevel</span><span class="o">(</span><span class="nv">Level</span><span class="o">.</span><span class="py">INFO</span><span class="o">)</span>
<span class="k">implicit</span> <span class="k">lazy</span> <span class="k">val</span> <span class="nv">spark</span><span class="k">:</span> <span class="kt">SparkSession</span> <span class="o">=</span> <span class="nv">SparkSession</span><span class="o">.</span><span class="py">builder</span><span class="o">().</span><span class="py">config</span><span class="o">(</span><span class="s">"spark.driver.bindAddress"</span><span class="o">,</span> <span class="s">"127.0.0.1"</span><span class="o">).</span><span class="py">master</span><span class="o">(</span><span class="s">"local[*]"</span><span class="o">).</span><span class="py">getOrCreate</span><span class="o">()</span>
</code></pre></div></div>

<p><strong>Define ETL Step which will load ratings data with below schema as specified from CSV to ORC</strong></p>

<div class="language-scala highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">import</span> <span class="nn">org.apache.spark.sql.SaveMode</span>
<span class="k">import</span> <span class="nn">etlflow.etlsteps.SparkReadWriteStep</span>
<span class="k">import</span> <span class="nn">etlflow.spark.IOType</span>
<span class="k">import</span> <span class="nn">etlflow.gcp.BQInputType</span>
    
<span class="k">case</span> <span class="k">class</span> <span class="nc">Rating</span><span class="o">(</span><span class="n">user_id</span><span class="k">:</span><span class="kt">Int</span><span class="o">,</span> <span class="n">movie_id</span><span class="k">:</span> <span class="kt">Int</span><span class="o">,</span> <span class="n">rating</span> <span class="k">:</span> <span class="kt">Double</span><span class="o">,</span> <span class="n">timestamp</span><span class="k">:</span> <span class="kt">Long</span><span class="o">)</span>
        
<span class="k">lazy</span> <span class="k">val</span> <span class="nv">step1</span> <span class="k">=</span> <span class="nc">SparkReadWriteStep</span><span class="o">[</span><span class="kt">Rating</span><span class="o">](</span>
        <span class="n">name</span>                       <span class="k">=</span> <span class="s">"ConvertRatingsCSVtoORC"</span><span class="o">,</span>
        <span class="n">input_location</span>             <span class="k">=</span> <span class="nc">Seq</span><span class="o">(</span><span class="nf">job_properties</span><span class="o">(</span><span class="s">"ratings_input_path"</span><span class="o">)),</span>
        <span class="n">input_type</span>                 <span class="k">=</span> <span class="nv">IOType</span><span class="o">.</span><span class="py">CSV</span><span class="o">(),</span>
        <span class="n">output_location</span>            <span class="k">=</span> <span class="nf">job_properties</span><span class="o">(</span><span class="s">"ratings_output_path"</span><span class="o">),</span>
        <span class="n">output_type</span>                <span class="k">=</span> <span class="nv">IOType</span><span class="o">.</span><span class="py">ORC</span><span class="o">,</span>
        <span class="n">output_save_mode</span>           <span class="k">=</span> <span class="nv">SaveMode</span><span class="o">.</span><span class="py">Overwrite</span><span class="o">,</span>
        <span class="n">output_repartitioning_num</span>  <span class="k">=</span> <span class="mi">1</span><span class="o">,</span>
        <span class="n">output_repartitioning</span>      <span class="k">=</span> <span class="kc">true</span><span class="o">,</span>
        <span class="n">output_filename</span>            <span class="k">=</span> <span class="nc">Some</span><span class="o">(</span><span class="nf">job_properties</span><span class="o">(</span><span class="s">"ratings_output_file_name"</span><span class="o">))</span>
<span class="o">)</span>
</code></pre></div></div>

<p><strong>Since all these steps return Task from ZIO library, we need to import Zio Default Runtime to run these steps</strong></p>

<div class="language-scala highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">import</span> <span class="nn">zio.</span><span class="o">{</span><span class="nc">Runtime</span><span class="o">,</span><span class="nc">ZEnv</span><span class="o">}</span>
</code></pre></div></div>

<p><strong>Run this step as below</strong></p>

<div class="language-scala highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">val</span> <span class="nv">task</span> <span class="k">=</span> <span class="nv">step1</span><span class="o">.</span><span class="py">process</span><span class="o">()</span>
<span class="c1">// task: zio.package.Task[Unit] = zio.ZIO$EffectPartial@3bf34f13</span>
</code></pre></div></div>

<p><strong>Now executing above step has added data in ORC format in path defined in above properties upon completion.</strong></p>

<p><strong>This is very basic example for flat load from CSV to ORC but lets say you need to transform csv data in some way for e.g. new column need to be added then we need to create function with below signature:</strong></p>

<div class="language-scala highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">import</span> <span class="nn">org.apache.spark.sql.</span><span class="o">{</span><span class="nc">Encoders</span><span class="o">,</span> <span class="nc">Dataset</span><span class="o">}</span>
<span class="k">import</span> <span class="nn">org.apache.spark.sql.types.DateType</span>
<span class="k">import</span> <span class="nn">org.apache.spark.sql.functions._</span>
<span class="k">import</span> <span class="nn">etlflow.spark.IOType</span>
<span class="k">import</span> <span class="nn">etlflow.gcp.BQInputType</span>
     
<span class="k">case</span> <span class="k">class</span> <span class="nc">RatingOutput</span><span class="o">(</span><span class="n">user_id</span><span class="k">:</span><span class="kt">Int</span><span class="o">,</span> <span class="n">movie_id</span><span class="k">:</span> <span class="kt">Int</span><span class="o">,</span> <span class="n">rating</span><span class="k">:</span> <span class="kt">Double</span><span class="o">,</span> <span class="n">timestamp</span><span class="k">:</span> <span class="kt">Long</span><span class="o">,</span> <span class="n">date</span><span class="k">:</span> <span class="kt">java.sql.Date</span><span class="o">)</span>
     
<span class="k">def</span> <span class="nf">enrichRatingData</span><span class="o">(</span><span class="n">spark</span><span class="k">:</span> <span class="kt">SparkSession</span><span class="o">,</span> <span class="n">in</span> <span class="k">:</span> <span class="kt">Dataset</span><span class="o">[</span><span class="kt">Rating</span><span class="o">])</span><span class="k">:</span> <span class="kt">Dataset</span><span class="o">[</span><span class="kt">RatingOutput</span><span class="o">]</span> <span class="k">=</span> <span class="o">{</span>
         <span class="k">val</span> <span class="nv">mapping</span> <span class="k">=</span> <span class="nv">Encoders</span><span class="o">.</span><span class="py">product</span><span class="o">[</span><span class="kt">RatingOutput</span><span class="o">]</span>
     
         <span class="k">val</span> <span class="nv">ratings_df</span> <span class="k">=</span> <span class="n">in</span>
             <span class="o">.</span><span class="py">withColumn</span><span class="o">(</span><span class="s">"date"</span><span class="o">,</span> <span class="nf">from_unixtime</span><span class="o">(</span><span class="nf">col</span><span class="o">(</span><span class="s">"timestamp"</span><span class="o">),</span> <span class="s">"yyyy-MM-dd"</span><span class="o">).</span><span class="py">cast</span><span class="o">(</span><span class="nc">DateType</span><span class="o">))</span>
         
         <span class="nv">ratings_df</span><span class="o">.</span><span class="py">as</span><span class="o">[</span><span class="kt">RatingOutput</span><span class="o">](</span><span class="n">mapping</span><span class="o">)</span>
<span class="o">}</span>
</code></pre></div></div>
<p><strong>Now our step would change to something like this</strong></p>

<div class="language-scala highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">lazy</span> <span class="k">val</span> <span class="nv">step2</span> <span class="k">=</span> <span class="nc">SparkReadTransformWriteStep</span><span class="o">[</span><span class="kt">Rating</span>, <span class="kt">RatingOutput</span><span class="o">](</span>
         <span class="n">name</span>                       <span class="k">=</span> <span class="s">"ConvertRatingsCSVtoORC"</span><span class="o">,</span>
         <span class="n">input_location</span>             <span class="k">=</span> <span class="nc">Seq</span><span class="o">(</span><span class="nf">job_properties</span><span class="o">(</span><span class="s">"ratings_input_path"</span><span class="o">)),</span>
         <span class="n">input_type</span>                 <span class="k">=</span> <span class="nv">IOType</span><span class="o">.</span><span class="py">CSV</span><span class="o">(),</span>
         <span class="n">transform_function</span>         <span class="k">=</span> <span class="n">enrichRatingData</span><span class="o">,</span>
         <span class="n">output_type</span>                <span class="k">=</span> <span class="nv">IOType</span><span class="o">.</span><span class="py">ORC</span><span class="o">,</span>
         <span class="n">output_save_mode</span>           <span class="k">=</span> <span class="nv">SaveMode</span><span class="o">.</span><span class="py">Overwrite</span><span class="o">,</span>
         <span class="n">output_location</span>            <span class="k">=</span> <span class="nf">job_properties</span><span class="o">(</span><span class="s">"ratings_output_path"</span><span class="o">),</span>
         <span class="n">output_repartitioning_num</span>  <span class="k">=</span> <span class="mi">1</span><span class="o">,</span>
         <span class="n">output_repartitioning</span>      <span class="k">=</span> <span class="kc">true</span><span class="o">,</span>
         <span class="n">output_filename</span>            <span class="k">=</span> <span class="nc">Some</span><span class="o">(</span><span class="nf">job_properties</span><span class="o">(</span><span class="s">"ratings_output_file_name"</span><span class="o">))</span>
<span class="o">)</span>
     
<span class="k">val</span> <span class="nv">task1</span> <span class="k">=</span> <span class="nv">step1</span><span class="o">.</span><span class="py">process</span><span class="o">()</span>
<span class="c1">// task1: zio.package.Task[Unit] = zio.ZIO$EffectPartial@6018d38c</span>
</code></pre></div></div>
<p><strong>Lets add another step which will copy this transformed ORC data in BigQuery table. 
For this step to work correctly <a href="https://cloud.google.com/sdk/install">Google Cloud SDK</a> needs to be installed and configured, 
as in this library upload from local file to BigQuery uses <a href="https://cloud.google.com/bigquery/docs/bq-command-line-tool">bq command</a> which is only recommended to be used in testing environments as in production files should be present on Google Cloud Storage when uploading to BigQuery</strong></p>

<div class="language-scala highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">import</span> <span class="nn">etlflow.spark.IOType</span>
<span class="k">import</span> <span class="nn">etlflow.gcp.BQInputType</span>
<span class="c1">// Adding two new properties for Bigquery table and Dataset</span>
       <span class="k">lazy</span> <span class="k">val</span> <span class="nv">job_properties1</span><span class="k">:</span> <span class="kt">Map</span><span class="o">[</span><span class="kt">String</span>,<span class="kt">String</span><span class="o">]</span> <span class="k">=</span> <span class="nc">Map</span><span class="o">(</span>
        <span class="s">"ratings_input_path"</span> <span class="o">-&gt;</span> <span class="n">s</span><span class="s">"$canonical_path/examples/src/main/data/movies/ratings/*"</span><span class="o">,</span>
        <span class="s">"ratings_output_path"</span> <span class="o">-&gt;</span> <span class="n">s</span><span class="s">"$canonical_path/examples/src/main/data/movies/output/ratings"</span><span class="o">,</span>
        <span class="s">"ratings_output_file_name"</span> <span class="o">-&gt;</span> <span class="s">"ratings.orc"</span><span class="o">,</span>
        <span class="s">"ratings_output_dataset"</span> <span class="o">-&gt;</span> <span class="s">"test"</span><span class="o">,</span>
        <span class="s">"ratings_output_table_name"</span> <span class="o">-&gt;</span> <span class="s">"ratings"</span>
<span class="o">)</span>
    
<span class="k">lazy</span>  <span class="k">val</span> <span class="nv">step3</span> <span class="k">=</span> <span class="nc">BQLoadStep</span><span class="o">(</span>
        <span class="n">name</span>                <span class="k">=</span> <span class="s">"LoadRatingBQ"</span><span class="o">,</span>
        <span class="n">input_location</span>      <span class="k">=</span> <span class="nc">Left</span><span class="o">(</span><span class="nf">job_properties1</span><span class="o">(</span><span class="s">"ratings_output_path"</span><span class="o">)</span> <span class="o">+</span> <span class="s">"/"</span> <span class="o">+</span> <span class="nf">job_properties1</span><span class="o">(</span><span class="s">"ratings_output_file_name"</span><span class="o">)),</span>
        <span class="n">input_type</span>          <span class="k">=</span> <span class="nv">BQInputType</span><span class="o">.</span><span class="py">ORC</span><span class="o">,</span>
        <span class="n">output_dataset</span>      <span class="k">=</span> <span class="nf">job_properties1</span><span class="o">(</span><span class="s">"ratings_output_dataset"</span><span class="o">),</span>
        <span class="n">output_table</span>        <span class="k">=</span> <span class="nf">job_properties1</span><span class="o">(</span><span class="s">"ratings_output_table_name"</span><span class="o">)</span>
<span class="o">)</span>
    
<span class="k">val</span> <span class="nv">task2</span> <span class="k">=</span> <span class="nv">step2</span><span class="o">.</span><span class="py">process</span><span class="o">()</span>
<span class="c1">// task2: zio.package.Task[Unit] = zio.ZIO$EffectPartial@34f1dfaf</span>
</code></pre></div></div>
<p><strong>Now we can run also chain multiple steps together and run as single job as shown below.</strong></p>

<div class="language-scala highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">val</span> <span class="nv">job</span> <span class="k">=</span> <span class="k">for</span> <span class="o">{</span>
        <span class="k">_</span> <span class="k">&lt;-</span> <span class="nv">step1</span><span class="o">.</span><span class="py">process</span><span class="o">()</span>
        <span class="k">_</span> <span class="k">&lt;-</span> <span class="nv">step2</span><span class="o">.</span><span class="py">process</span><span class="o">()</span>
<span class="o">}</span> <span class="nf">yield</span> <span class="o">()</span>
<span class="c1">// job: zio.ZIO[Any, Throwable, Unit] = zio.ZIO$FlatMap@36d227d8</span>
</code></pre></div></div>

</section></div></div></div></div><script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/twitter-bootstrap/3.3.7/js/bootstrap.min.js"></script><script src="/etlflow/site/highlight/highlight.pack.js"></script><script src="/etlflow/site/lunr/lunr.js"></script><script>
// For all code blocks, copy the language from the containing div
// to the inner code tag (where hljs expects it to be)
const langPrefix = 'language-';
document.querySelectorAll(`div[class^='${langPrefix}']`).forEach(function(div) {
  div.classList.forEach(function(cssClass) {
    if (cssClass.startsWith(langPrefix)) {
      const lang = cssClass.substring(langPrefix.length);
      div.querySelectorAll('pre code').forEach(function(code) {
        code.classList.add(lang);
      });
    }
  });
});

hljs.configure({languages:['scala','java','bash']});
hljs.initHighlightingOnLoad();
      </script><script>console.info('\x57\x65\x62\x73\x69\x74\x65\x20\x62\x75\x69\x6c\x74\x20\x77\x69\x74\x68\x3a\x0a\x20\x20\x20\x20\x20\x20\x20\x20\x20\x5f\x5f\x20\x20\x20\x20\x5f\x5f\x20\x20\x20\x20\x20\x20\x20\x20\x20\x20\x20\x20\x20\x20\x20\x20\x20\x20\x5f\x20\x20\x20\x20\x20\x20\x20\x20\x20\x20\x20\x20\x20\x20\x20\x20\x20\x20\x20\x20\x20\x20\x5f\x20\x5f\x5f\x0a\x20\x20\x20\x5f\x5f\x5f\x5f\x5f\x2f\x20\x2f\x5f\x20\x20\x2f\x20\x2f\x5f\x20\x20\x20\x20\x20\x20\x5f\x5f\x5f\x5f\x20\x5f\x5f\x5f\x20\x20\x28\x5f\x29\x5f\x5f\x5f\x5f\x5f\x5f\x5f\x5f\x5f\x5f\x5f\x5f\x5f\x20\x20\x5f\x5f\x5f\x5f\x5f\x28\x5f\x29\x20\x2f\x5f\x5f\x5f\x5f\x20\x20\x5f\x5f\x5f\x5f\x5f\x0a\x20\x20\x2f\x20\x5f\x5f\x5f\x2f\x20\x5f\x5f\x20\x5c\x2f\x20\x5f\x5f\x2f\x5f\x5f\x5f\x5f\x5f\x2f\x20\x5f\x5f\x20\x60\x5f\x5f\x20\x5c\x2f\x20\x2f\x20\x5f\x5f\x5f\x2f\x20\x5f\x5f\x5f\x2f\x20\x5f\x5f\x20\x5c\x2f\x20\x5f\x5f\x5f\x2f\x20\x2f\x20\x5f\x5f\x2f\x20\x5f\x20\x5c\x2f\x20\x5f\x5f\x5f\x2f\x0a\x20\x28\x5f\x5f\x20\x20\x29\x20\x2f\x5f\x2f\x20\x2f\x20\x2f\x5f\x2f\x5f\x5f\x5f\x5f\x5f\x2f\x20\x2f\x20\x2f\x20\x2f\x20\x2f\x20\x2f\x20\x2f\x20\x2f\x5f\x5f\x2f\x20\x2f\x20\x20\x2f\x20\x2f\x5f\x2f\x20\x28\x5f\x5f\x20\x20\x29\x20\x2f\x20\x2f\x5f\x2f\x20\x20\x5f\x5f\x28\x5f\x5f\x20\x20\x29\x0a\x2f\x5f\x5f\x5f\x5f\x2f\x5f\x2e\x5f\x5f\x5f\x2f\x5c\x5f\x5f\x2f\x20\x20\x20\x20\x20\x2f\x5f\x2f\x20\x2f\x5f\x2f\x20\x2f\x5f\x2f\x5f\x2f\x5c\x5f\x5f\x5f\x2f\x5f\x2f\x20\x20\x20\x5c\x5f\x5f\x5f\x5f\x2f\x5f\x5f\x5f\x5f\x2f\x5f\x2f\x5c\x5f\x5f\x2f\x5c\x5f\x5f\x5f\x2f\x5f\x5f\x5f\x5f\x2f\x0a\x0a\x68\x74\x74\x70\x73\x3a\x2f\x2f\x34\x37\x64\x65\x67\x2e\x67\x69\x74\x68\x75\x62\x2e\x69\x6f\x2f\x73\x62\x74\x2d\x6d\x69\x63\x72\x6f\x73\x69\x74\x65\x73')</script><script src="/etlflow/site/js/search.js"></script><script src="/etlflow/site/js/main.js"></script></body></html>