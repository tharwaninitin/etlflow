<!DOCTYPE html><html><head><title>EtlFlow: Using with Hadoop Cluster</title><meta charset="utf-8" /><meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" /><meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="author" content="com.github.tharwaninitin" /><meta name="description" content="Functional library in Scala for writing ETL jobs" /><meta name="og:image" content="/etlflow/site/img/poster.png" /><meta name="image" property="og:image" content="/etlflow/site/img/poster.png" /><meta name="og:title" content="EtlFlow: Using with Hadoop Cluster" /><meta name="title" property="og:title" content="EtlFlow: Using with Hadoop Cluster" /><meta name="og:site_name" content="EtlFlow" /><meta name="og:url" content="" /><meta name="og:type" content="website" /><meta name="og:description" content="Functional library in Scala for writing ETL jobs" /><link rel="icon" type="image/png" href="/etlflow/site/img/favicon.png" /><meta name="twitter:title" content="EtlFlow: Using with Hadoop Cluster" /><meta name="twitter:image" content="https://tharwaninitin.github.io/etlflow/site//etlflow/site/img/poster.png" /><meta name="twitter:description" content="Functional library in Scala for writing ETL jobs" /><meta name="twitter:card" content="summary_large_image" /><link rel="icon" type="image/png" sizes="16x16" href="/etlflow/site/img/favicon16x16.png" /><link rel="icon" type="image/png" sizes="24x24" href="/etlflow/site/img/favicon24x24.png" /><link rel="icon" type="image/png" sizes="32x32" href="/etlflow/site/img/favicon32x32.png" /><link rel="icon" type="image/png" sizes="48x48" href="/etlflow/site/img/favicon48x48.png" /><link rel="icon" type="image/png" sizes="57x57" href="/etlflow/site/img/favicon57x57.png" /><link rel="icon" type="image/png" sizes="60x60" href="/etlflow/site/img/favicon60x60.png" /><link rel="icon" type="image/png" sizes="64x64" href="/etlflow/site/img/favicon64x64.png" /><link rel="icon" type="image/png" sizes="70x70" href="/etlflow/site/img/favicon70x70.png" /><link rel="icon" type="image/png" sizes="72x72" href="/etlflow/site/img/favicon72x72.png" /><link rel="icon" type="image/png" sizes="76x76" href="/etlflow/site/img/favicon76x76.png" /><link rel="icon" type="image/png" sizes="96x96" href="/etlflow/site/img/favicon96x96.png" /><link rel="icon" type="image/png" sizes="114x114" href="/etlflow/site/img/favicon114x114.png" /><link rel="icon" type="image/png" sizes="120x120" href="/etlflow/site/img/favicon120x120.png" /><link rel="icon" type="image/png" sizes="128x128" href="/etlflow/site/img/favicon128x128.png" /><link rel="icon" type="image/png" sizes="144x144" href="/etlflow/site/img/favicon144x144.png" /><link rel="icon" type="image/png" sizes="150x150" href="/etlflow/site/img/favicon150x150.png" /><link rel="icon" type="image/png" sizes="152x152" href="/etlflow/site/img/favicon152x152.png" /><link rel="icon" type="image/png" sizes="196x196" href="/etlflow/site/img/favicon196x196.png" /><link rel="icon" type="image/png" sizes="310x310" href="/etlflow/site/img/favicon310x310.png" /><link rel="icon" type="image/png" sizes="310x150" href="/etlflow/site/img/favicon310x150.png" /><link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/bootstrap/3.3.7/css/bootstrap.min.css" /><link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/font-awesome/4.7.0/css/font-awesome.min.css" /><link rel="stylesheet" href="/etlflow/site/highlight/styles/vs.css" /><link rel="stylesheet" href="/etlflow/site/css/pattern-style.css" /></head><body class="docs"><div id="wrapper"><div id="sidebar-wrapper"><ul id="sidebar" class="sidebar-nav"><li class="sidebar-brand"><a href="/etlflow/site/" class="brand"><div class="brand-wrapper"><span>EtlFlow</span></div></a></li> <li><a href="/etlflow/site/docs/index.html" class="">Introduction</a></li> <li><a href="/etlflow/site/docs/quickstart.html" class="">Quick Start</a></li> <li><a href="/etlflow/site/docs/components.html" class="">Components</a> <ul class="sub-section"> <li><a href="/etlflow/site/docs/core.html" class="">Core</a></li> <li><a href="/etlflow/site/docs/cloud.html" class="">Cloud</a></li> <li><a href="/etlflow/site/docs/spark_components.html" class="">Spark</a></li> <li><a href="/etlflow/site/docs/server.html" class="">Server</a></li></ul></li> <li><a href="/etlflow/site/docs/usage.html" class="">Deployments</a> <ul class="sub-section"> <li><a href="/etlflow/site/docs/gcpdp.html" class="">Core (Dataproc)</a></li> <li><a href="/etlflow/site/docs/hdfs.html" class="">Core (Hdfs)</a></li> <li><a href="/etlflow/site/docs/localdocker.html" class="">Server (Local Docker)</a></li> <li><a href="/etlflow/site/docs/gke.html" class="">Server (Kubernetes)</a></li></ul></li> <li><a href="/etlflow/site/docs/steps.html" class="">Steps</a> <ul class="sub-section"> <li><a href="/etlflow/site/docs/spark.html" class="">Spark</a></li> <li><a href="/etlflow/site/docs/bigquery.html" class="">BigQuery</a></li> <li><a href="/etlflow/site/docs/gcs.html" class="">GCS</a></li> <li><a href="/etlflow/site/docs/s3.html" class="">S3</a></li> <li><a href="/etlflow/site/docs/jdbc.html" class="">JDBC</a></li> <li><a href="/etlflow/site/docs/http.html" class="">HTTP</a></li> <li><a href="/etlflow/site/docs/redisquery.html" class="">Redis</a></li> <li><a href="/etlflow/site/docs/sendmail.html" class="">Send Mail</a></li> <li><a href="/etlflow/site/docs/dp.html" class="">Dataproc</a></li> <li><a href="/etlflow/site/docs/parallel.html" class="">Parallel Step Execution</a></li> <li><a href="/etlflow/site/docs/cloud_steps.html" class="">Cloud</a></li> <li><a href="/etlflow/site/docs/remote.html" class="">Remote</a></li></ul></li> <li><a href="/etlflow/site/docs/sensors.html" class="">Sensors</a> <ul class="sub-section"> <li><a href="/etlflow/site/docs/gcssensor.html" class="">GCS Sensor</a></li> <li><a href="/etlflow/site/docs/s3sensor.html" class="">S3 Sensor</a></li></ul></li> <li><a href="/etlflow/site/docs/job.html" class="">Job</a></li> <li><a href="/etlflow/site/docs/executors.html" class="">Executors</a> <ul class="sub-section"> <li><a href="/etlflow/site/docs/local.html" class="">Local Executor</a></li> <li><a href="/etlflow/site/docs/local_subprocess.html" class="">Local Sub-Process Executor</a></li> <li><a href="/etlflow/site/docs/dataproc.html" class="">Dataproc Executor</a></li> <li><a href="/etlflow/site/docs/kubernetes.html" class="">Kubernetes Executor</a></li></ul></li></ul></div><div id="page-content-wrapper"><div class="nav"><div class="container-fluid"><div class="row"><div class="col-lg-12"><div class="action-menu pull-left clearfix"><a href="#menu-toggle" id="menu-toggle"><i class="fa fa-bars" aria-hidden="true"></i></a></div><ul class="pull-right"><li id="gh-eyes-item" class="hidden-xs"><a href="https://github.com/tharwaninitin/etlflow" target="_blank" rel="noopener noreferrer"><i class="fa fa-eye"></i><span>Watchers<span id="eyes" class="label label-default">--</span></span></a></li><li id="gh-stars-item" class="hidden-xs"><a href="https://github.com/tharwaninitin/etlflow" target="_blank" rel="noopener noreferrer"><i class="fa fa-star-o"></i><span>Stars<span id="stars" class="label label-default">--</span></span></a></li><li><a href="#" onclick="shareSiteTwitter('EtlFlow Functional library in Scala for writing ETL jobs');"><i class="fa fa-twitter"></i></a></li><li><a href="#" onclick="shareSiteFacebook('EtlFlow Functional library in Scala for writing ETL jobs');"><i class="fa fa-facebook"></i></a></li><li><a href="#" onclick="shareSiteGoogle();"><i class="fa fa-google-plus"></i></a></li></ul></div></div></div></div><div id="content" data-github-owner="tharwaninitin" data-github-repo="etlflow"><div class="content-wrapper"><section><h2 id="using-etlflow-core-library-in-your-etl-projects-on-hadoop-cluster">Using Etlflow core library in your ETL projects on Hadoop Cluster.</h2>

<h3 id="prerequisite">Prerequisite</h3>
<ul>
  <li>Your system should have one of the below distribution installed machine :
    <ol>
      <li><a href="https://www.cloudera.com/">Cloudera</a>.</li>
      <li><a href="https://www.cloudera.com/downloads/hortonworks-sandbox.html">Hortonworks</a>.</li>
      <li><a href="https://mapr.com/try-mapr/">MapR</a></li>
    </ol>
  </li>
  <li>You should have Hadoop cluster created.</li>
  <li>You should appropriate permissions for GCS, BigQuery, Submitting jobs on Hadoop etc</li>
</ul>

<h3 id="step-1-building-a-jar-for-application-here-we-will-take-examples-scala-project-in-this-library">STEP 1) Building a jar for application, here we will take examples scala project in this library</h3>

<ul>
  <li>
    <p>To build jar for an application perform below commands from project root folder:</p>

    <div class="highlighter-rouge"><pre class="highlight"><code>&gt; sbt
&gt; project examples
&gt; package
</code></pre>
    </div>
  </li>
  <li>From root folder run ‘sbt’ command</li>
  <li>Inside sbt, Run ‘project examples’ to set the current project as examples.</li>
  <li>Once project gets set then run ‘package’ to build an assembly jar.</li>
</ul>

<h3 id="step-2-building-an-assembly-jar-for-etlflow-core">STEP 2) Building an assembly jar for etlflow core</h3>
<p>To build an assembly jar for an etlflow core library we need to perform some steps. Clone this git repo and go inside repo root folder and perform below steps:</p>

<div class="highlighter-rouge"><pre class="highlight"><code>  &gt; sbt
  &gt; project core
  &gt; assembly
</code></pre>
</div>

<ul>
  <li>Inside root folder run ‘sbt’ command</li>
  <li>Inside sbt, Run ‘project core’ to set the current project as etlflow-core</li>
  <li>Once project gets set then run ‘assembly’ to build an assembly jar.</li>
</ul>

<h3 id="step-3-copy-the-etlflow-core-assembly-jar-to-hdfs-location--using-below-command">STEP 3) Copy the etlflow core assembly jar to hdfs location  using below command</h3>

<div class="highlighter-rouge"><pre class="highlight"><code>  hdfs dfs -copyFromLocal modules/core/target/scala-2.12/etlflow-core-assembly-x.x.x.jar hdfs://&lt;HDFS_destination&gt;/jars/etlflow
</code></pre>
</div>

<p>Replace x.x.x with the latest version <a href="https://mvnrepository.com/artifact/com.github.tharwaninitin/etlflow-core"><img src="https://maven-badges.herokuapp.com/maven-central/com.github.tharwaninitin/etlflow-core_2.12/badge.svg" alt="Maven Central" /></a></p>

<h3 id="step-4-copy-the-examples-jar-to-hdfs-location-using-below-command">STEP 4) Copy the examples jar to hdfs location using below command:</h3>

<div class="highlighter-rouge"><pre class="highlight"><code>  hdfs dfs -copyFromLocal  examples/target/scala-2.12/etlflow-examples_2.12-x.x.x.jar  hdfs://&lt;HDFS_destination&gt;/jars/etlflow
</code></pre>
</div>

<p>Replace x.x.x with the latest version <a href="https://mvnrepository.com/artifact/com.github.tharwaninitin/etlflow-core"><img src="https://maven-badges.herokuapp.com/maven-central/com.github.tharwaninitin/etlflow-core_2.12/badge.svg" alt="Maven Central" /></a></p>

<h3 id="step-5-provide-below-detials-in-file-examplessrcmainresourcesapplicationconf">STEP 5) Provide below detials in file <strong>examples/src/main/resources/application.conf</strong>:</h3>

<div class="highlighter-rouge"><pre class="highlight"><code>    dbLog = {
      url = &lt;log_db_url&gt;,
      user = &lt;log_db_user&gt;,
      password = &lt;log_db_pwd&gt;,
      driver = "org.postgresql.Driver"
    }
    slack =  {
      url = &lt;slack-url&gt;,
      env = &lt;running-env&gt;
    }
</code></pre>
</div>

<ul>
  <li>
    <p>Now Copy updated application.conf file at hdfs location using below command:</p>

    <div class="highlighter-rouge"><pre class="highlight"><code>  hdfs dfs -copyFromLocal examples/src/main/resources/application.conf   hdfs://&lt;HDFS_destination&gt;/jars/etlflow
</code></pre>
    </div>
  </li>
  <li>
    <p>Copy the input file present at location examples/src/main/data/movies/ratings_parquet/ratings.parquet for running sample job using below command:</p>

    <div class="highlighter-rouge"><pre class="highlight"><code>  hdfs dfs -copyFromLocal examples/src/main/data/movies/ratings_parquet/ratings.parquet   hdfs://&lt;HDFS_destination&gt;/jars/etlflow
</code></pre>
    </div>
  </li>
</ul>

<h3 id="step-6-now-finally-we-can-run-sample-job-on-hadoop-cluster-using-below-command">STEP 6) Now finally we can run sample job on Hadoop cluster using below command:</h3>

<div class="highlighter-rouge"><pre class="highlight"><code>    spark-submit \
     --master yarn \
     --deploy-mode cluster \
     --driver-memory 8g \
     --executor-memory 16g \
     --class examples.LoadData  \
      hdfs://&lt;HDFS_destination&gt;/jars/examples/etlflow-examples_2.12-0.7.19.jar,hdfs://&lt;HDFS_destination&gt;/jars/examples/etlflow-core-assembly-0.7.19.jar \
      run_job --job_name EtlJob1PARQUETtoORCtoBQLocalWith2Steps  --props ratings_input_path=hdfs://&lt;HDFS_destination&gt;/examples/input,ratings_output_table_name=ratings,ratings_output_dataset=test,ratings_output_file_name=ratings.orc
</code></pre>
</div>

</section></div></div></div></div><script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/twitter-bootstrap/3.3.7/js/bootstrap.min.js"></script><script src="/etlflow/site/highlight/highlight.pack.js"></script><script>
// For all code blocks, copy the language from the containing div
// to the inner code tag (where hljs expects it to be)
const langPrefix = 'language-';
document.querySelectorAll(`div[class^='${langPrefix}']`).forEach(function(div) {
  div.classList.forEach(function(cssClass) {
    if (cssClass.startsWith(langPrefix)) {
      const lang = cssClass.substring(langPrefix.length);
      div.querySelectorAll('pre code').forEach(function(code) {
        code.classList.add(lang);
      });
    }
  });
});

hljs.configure({languages:['scala','java','bash']});
hljs.initHighlightingOnLoad();
      </script><script>console.info('\x57\x65\x62\x73\x69\x74\x65\x20\x62\x75\x69\x6c\x74\x20\x77\x69\x74\x68\x3a\x0a\x20\x20\x20\x20\x20\x20\x20\x20\x20\x5f\x5f\x20\x20\x20\x20\x5f\x5f\x20\x20\x20\x20\x20\x20\x20\x20\x20\x20\x20\x20\x20\x20\x20\x20\x20\x20\x5f\x20\x20\x20\x20\x20\x20\x20\x20\x20\x20\x20\x20\x20\x20\x20\x20\x20\x20\x20\x20\x20\x20\x5f\x20\x5f\x5f\x0a\x20\x20\x20\x5f\x5f\x5f\x5f\x5f\x2f\x20\x2f\x5f\x20\x20\x2f\x20\x2f\x5f\x20\x20\x20\x20\x20\x20\x5f\x5f\x5f\x5f\x20\x5f\x5f\x5f\x20\x20\x28\x5f\x29\x5f\x5f\x5f\x5f\x5f\x5f\x5f\x5f\x5f\x5f\x5f\x5f\x5f\x20\x20\x5f\x5f\x5f\x5f\x5f\x28\x5f\x29\x20\x2f\x5f\x5f\x5f\x5f\x20\x20\x5f\x5f\x5f\x5f\x5f\x0a\x20\x20\x2f\x20\x5f\x5f\x5f\x2f\x20\x5f\x5f\x20\x5c\x2f\x20\x5f\x5f\x2f\x5f\x5f\x5f\x5f\x5f\x2f\x20\x5f\x5f\x20\x60\x5f\x5f\x20\x5c\x2f\x20\x2f\x20\x5f\x5f\x5f\x2f\x20\x5f\x5f\x5f\x2f\x20\x5f\x5f\x20\x5c\x2f\x20\x5f\x5f\x5f\x2f\x20\x2f\x20\x5f\x5f\x2f\x20\x5f\x20\x5c\x2f\x20\x5f\x5f\x5f\x2f\x0a\x20\x28\x5f\x5f\x20\x20\x29\x20\x2f\x5f\x2f\x20\x2f\x20\x2f\x5f\x2f\x5f\x5f\x5f\x5f\x5f\x2f\x20\x2f\x20\x2f\x20\x2f\x20\x2f\x20\x2f\x20\x2f\x20\x2f\x5f\x5f\x2f\x20\x2f\x20\x20\x2f\x20\x2f\x5f\x2f\x20\x28\x5f\x5f\x20\x20\x29\x20\x2f\x20\x2f\x5f\x2f\x20\x20\x5f\x5f\x28\x5f\x5f\x20\x20\x29\x0a\x2f\x5f\x5f\x5f\x5f\x2f\x5f\x2e\x5f\x5f\x5f\x2f\x5c\x5f\x5f\x2f\x20\x20\x20\x20\x20\x2f\x5f\x2f\x20\x2f\x5f\x2f\x20\x2f\x5f\x2f\x5f\x2f\x5c\x5f\x5f\x5f\x2f\x5f\x2f\x20\x20\x20\x5c\x5f\x5f\x5f\x5f\x2f\x5f\x5f\x5f\x5f\x2f\x5f\x2f\x5c\x5f\x5f\x2f\x5c\x5f\x5f\x5f\x2f\x5f\x5f\x5f\x5f\x2f\x0a\x0a\x68\x74\x74\x70\x73\x3a\x2f\x2f\x34\x37\x64\x65\x67\x2e\x67\x69\x74\x68\x75\x62\x2e\x69\x6f\x2f\x73\x62\x74\x2d\x6d\x69\x63\x72\x6f\x73\x69\x74\x65\x73')</script><script src="/etlflow/site/js/main.js"></script></body></html>